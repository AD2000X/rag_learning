{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhpw64IDzMzs"
      },
      "source": [
        "# Configurartion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Xym23RLi6Cs6",
        "outputId": "a5b3f52d-a73c-4d75-c59e-34aa1f02fca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Collecting notebook==7.1.2\n",
            "  Downloading notebook-7.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Collecting elasticsearch\n",
            "  Downloading elasticsearch-8.15.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from notebook==7.1.2)\n",
            "  Downloading jupyter_server-2.14.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.22.1 (from notebook==7.1.2)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jupyterlab<4.2,>=4.1.1 (from notebook==7.1.2)\n",
            "  Downloading jupyterlab-4.1.8-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from notebook==7.1.2) (0.2.4)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from notebook==7.1.2) (6.3.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Collecting elastic-transport<9,>=8.13 (from elasticsearch)\n",
            "  Downloading elastic_transport-8.15.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch) (2.2.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.1.2) (23.1.0)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.1.2) (3.1.4)\n",
            "Collecting jupyter-client (from ipykernel>=4.5.1->ipywidgets)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.1.2) (5.7.2)\n",
            "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->notebook==7.1.2)\n",
            "  Downloading jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->notebook==7.1.2)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.1.2) (7.16.4)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.1.2) (5.10.4)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->notebook==7.1.2)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.1.2) (24.1)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.1.2) (0.21.0)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.1.2) (24.0.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.1.2) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.1.2) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.1.2) (1.8.0)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab<4.2,>=4.1.1->notebook==7.1.2)\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting ipykernel>=4.5.1 (from ipywidgets)\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab<4.2,>=4.1.1->notebook==7.1.2)\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tomli>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab<4.2,>=4.1.1->notebook==7.1.2) (2.0.2)\n",
            "Collecting comm>=0.1.1 (from ipykernel>=4.5.1->ipywidgets)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.6)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.22.1->notebook==7.1.2) (2.16.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.22.1->notebook==7.1.2)\n",
            "  Downloading json5-0.9.25-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.22.1->notebook==7.1.2) (4.23.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.22.1->notebook==7.1.2) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook==7.1.2) (21.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook==7.1.2) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook==7.1.2) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook==7.1.2) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook==7.1.2) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook==7.1.2) (0.20.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook==7.1.2) (4.3.6)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook==7.1.2)\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook==7.1.2) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook==7.1.2)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook==7.1.2)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.1.2) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.1.2) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.1.2) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.1.2) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.1.2) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.1.2) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.1.2) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.1.2) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook==7.1.2) (2.20.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook==7.1.2) (3.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.1.2) (0.5.1)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook==7.1.2)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook==7.1.2)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook==7.1.2) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook==7.1.2)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook==7.1.2) (24.8.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook==7.1.2) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.1.2) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook==7.1.2) (2.22)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook==7.1.2)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook==7.1.2)\n",
            "  Downloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl.metadata (1.9 kB)\n",
            "Downloading notebook-7.1.2-py3-none-any.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading elasticsearch-8.15.1-py3-none-any.whl (524 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.6/524.6 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading elastic_transport-8.15.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.14.2-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.1.8-py3-none-any.whl (11.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.9.25-py3-none-any.whl (30 kB)\n",
            "Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
            "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl (9.7 kB)\n",
            "Installing collected packages: uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, json5, jedi, fqdn, elastic-transport, comm, async-lru, jupyter-server-terminals, jupyter-client, elasticsearch, arrow, isoduration, ipykernel, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, notebook\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "  Attempting uninstall: notebook\n",
            "    Found existing installation: notebook 6.5.5\n",
            "    Uninstalling notebook-6.5.5:\n",
            "      Successfully uninstalled notebook-6.5.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.29.5 which is incompatible.\n",
            "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 7.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arrow-1.3.0 async-lru-2.0.4 comm-0.2.2 elastic-transport-8.15.1 elasticsearch-8.15.1 fqdn-1.5.1 ipykernel-6.29.5 isoduration-20.11.0 jedi-0.19.1 json5-0.9.25 jupyter-client-8.6.3 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter-server-2.14.2 jupyter-server-terminals-0.5.3 jupyterlab-4.1.8 jupyterlab-server-2.27.3 notebook-7.1.2 overrides-7.7.0 python-json-logger-2.0.7 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 types-python-dateutil-2.9.0.20241003 uri-template-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm notebook==7.1.2 openai elasticsearch pandas scikit-learn ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8wV12Lx6PL9"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# acquire API key from Colab userdata and set as environment variable\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('oaitest')\n",
        "\n",
        "# create OpenAI client rather than pass the the API key directly\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qzISDzo6Z_M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "azFq0BXYYpno",
        "outputId": "9cf28646-128f-49ec-e9e0-949f91a33ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-05 15:03:05--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3832 (3.7K) [text/plain]\n",
            "Saving to: ‘minsearch.py’\n",
            "\n",
            "minsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-05 15:03:06 (82.6 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RsUbq0uXY3sp",
        "outputId": "1d34a4db-eeef-4c47-93ba-de731a6b42cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import pandas as pd\n",
            "\n",
            "from sklearn.feature_extraction.text import TfidfVectorizer\n",
            "from sklearn.metrics.pairwise import cosine_similarity\n",
            "\n",
            "import numpy as np\n",
            "\n",
            "\n",
            "class Index:\n",
            "    \"\"\"\n",
            "    A simple search index using TF-IDF and cosine similarity for text fields and exact matching for keyword fields.\n",
            "\n",
            "    Attributes:\n",
            "        text_fields (list): List of text field names to index.\n",
            "        keyword_fields (list): List of keyword field names to index.\n",
            "        vectorizers (dict): Dictionary of TfidfVectorizer instances for each text field.\n",
            "        keyword_df (pd.DataFrame): DataFrame containing keyword field data.\n",
            "        text_matrices (dict): Dictionary of TF-IDF matrices for each text field.\n",
            "        docs (list): List of documents indexed.\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(self, text_fields, keyword_fields, vectorizer_params={}):\n",
            "        \"\"\"\n",
            "        Initializes the Index with specified text and keyword fields.\n",
            "\n",
            "        Args:\n",
            "            text_fields (list): List of text field names to index.\n",
            "            keyword_fields (list): List of keyword field names to index.\n",
            "            vectorizer_params (dict): Optional parameters to pass to TfidfVectorizer.\n",
            "        \"\"\"\n",
            "        self.text_fields = text_fields\n",
            "        self.keyword_fields = keyword_fields\n",
            "\n",
            "        self.vectorizers = {field: TfidfVectorizer(**vectorizer_params) for field in text_fields}\n",
            "        self.keyword_df = None\n",
            "        self.text_matrices = {}\n",
            "        self.docs = []\n",
            "\n",
            "    def fit(self, docs):\n",
            "        \"\"\"\n",
            "        Fits the index with the provided documents.\n",
            "\n",
            "        Args:\n",
            "            docs (list of dict): List of documents to index. Each document is a dictionary.\n",
            "        \"\"\"\n",
            "        self.docs = docs\n",
            "        keyword_data = {field: [] for field in self.keyword_fields}\n",
            "\n",
            "        for field in self.text_fields:\n",
            "            texts = [doc.get(field, '') for doc in docs]\n",
            "            self.text_matrices[field] = self.vectorizers[field].fit_transform(texts)\n",
            "\n",
            "        for doc in docs:\n",
            "            for field in self.keyword_fields:\n",
            "                keyword_data[field].append(doc.get(field, ''))\n",
            "\n",
            "        self.keyword_df = pd.DataFrame(keyword_data)\n",
            "\n",
            "        return self\n",
            "\n",
            "    def search(self, query, filter_dict={}, boost_dict={}, num_results=10):\n",
            "        \"\"\"\n",
            "        Searches the index with the given query, filters, and boost parameters.\n",
            "\n",
            "        Args:\n",
            "            query (str): The search query string.\n",
            "            filter_dict (dict): Dictionary of keyword fields to filter by. Keys are field names and values are the values to filter by.\n",
            "            boost_dict (dict): Dictionary of boost scores for text fields. Keys are field names and values are the boost scores.\n",
            "            num_results (int): The number of top results to return. Defaults to 10.\n",
            "\n",
            "        Returns:\n",
            "            list of dict: List of documents matching the search criteria, ranked by relevance.\n",
            "        \"\"\"\n",
            "        query_vecs = {field: self.vectorizers[field].transform([query]) for field in self.text_fields}\n",
            "        scores = np.zeros(len(self.docs))\n",
            "\n",
            "        # Compute cosine similarity for each text field and apply boost\n",
            "        for field, query_vec in query_vecs.items():\n",
            "            sim = cosine_similarity(query_vec, self.text_matrices[field]).flatten()\n",
            "            boost = boost_dict.get(field, 1)\n",
            "            scores += sim * boost\n",
            "\n",
            "        # Apply keyword filters\n",
            "        for field, value in filter_dict.items():\n",
            "            if field in self.keyword_fields:\n",
            "                mask = self.keyword_df[field] == value\n",
            "                scores = scores * mask.to_numpy()\n",
            "\n",
            "        # Use argpartition to get top num_results indices\n",
            "        top_indices = np.argpartition(scores, -num_results)[-num_results:]\n",
            "        top_indices = top_indices[np.argsort(-scores[top_indices])]\n",
            "\n",
            "        # Filter out zero-score results\n",
            "        top_docs = [self.docs[i] for i in top_indices if scores[i] > 0]\n",
            "\n",
            "        return top_docs"
          ]
        }
      ],
      "source": [
        "!cat minsearch.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7cLXZ6pCY6vt",
        "outputId": "5b4c4916-753d-44ac-9cd0-18306005691f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File contents:\n",
            "import pandas as pd\n",
            "\n",
            "from sklearn.feature_extraction.text import TfidfVectorizer\n",
            "from sklearn.metrics.pairwise import cosine_similarity\n",
            "\n",
            "import numpy as np\n",
            "\n",
            "\n",
            "class Index:\n",
            "    \"\"\"\n",
            "    A simple search index using TF-IDF and cosine similarity for text fields and exact matching for keyword fields.\n",
            "\n",
            "    Attributes:\n",
            "        text_fields (list): List of text field names to index.\n",
            "        keyword_fields (list): List of keyword field names to index.\n",
            "        vectorizers (dict): Dictionary of TfidfVectorize\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\"\n",
        "response = requests.get(url)\n",
        "\n",
        "with open(\"minsearch.py\", \"w\") as f:\n",
        "    f.write(response.text)\n",
        "\n",
        "print(\"File contents:\")\n",
        "print(response.text[:500])  # Print the first 500 characters of the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiFQUGVJaE5C"
      },
      "outputs": [],
      "source": [
        "import minsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6TDd-Y6aa4S"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ou3EzXmbNIn"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/AD2000X/llm-zoomcamp/refs/heads/main/01-intro/documents.json\"\n",
        "response = requests.get(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b2cx5pGbYPH",
        "outputId": "8c20c480-53c2-4009-e7ff-379d5bda56c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON data loaded successfully\n",
            "Number of items in the JSON: 3\n"
          ]
        }
      ],
      "source": [
        "if response.status_code == 200:\n",
        "    doc_raw = json.loads(response.text)\n",
        "    print(\"JSON data loaded successfully\")\n",
        "    print(f\"Number of items in the JSON: {len(doc_raw)}\")\n",
        "else:\n",
        "    print(f\"Failed to fetch data. Status code: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc59SwaeccVz"
      },
      "outputs": [],
      "source": [
        "documents = []\n",
        "\n",
        "for course_dict in doc_raw:\n",
        "  for doc in course_dict['documents']:\n",
        "    doc['course'] = course_dict['course']\n",
        "    documents.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2kpMcbVgN_r"
      },
      "outputs": [],
      "source": [
        "index = minsearch.Index(\n",
        "    text_fields=[\"question\", \"text\", \"section\"],\n",
        "    keyword_fields=[\"course\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skSby_KmfmwC",
        "outputId": "16ccd65d-461c-4216-ee57-9113078beb95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<minsearch.Index at 0x7d6aec4dcdc0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "index.fit(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x98JuNaOlbQq"
      },
      "source": [
        "# 1.5 - The RAG Flow Cleaning and Modularizing Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BosMmg0Lw_PL"
      },
      "source": [
        "### build search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzcScAxV8--s"
      },
      "outputs": [],
      "source": [
        "def search(query):\n",
        "    boost = {'question': 3.0, 'section': 0.5}\n",
        "\n",
        "    results = index.search(\n",
        "        query=query,\n",
        "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
        "        boost_dict=boost,\n",
        "        num_results=10\n",
        "\n",
        "    )\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4070aBuvs7pK"
      },
      "source": [
        "### build prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahuCV9z4rJKO"
      },
      "outputs": [],
      "source": [
        "def build_prompt(query, search_results):\n",
        "    prompt_template = \"\"\"\n",
        "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
        "Use only the facts from the CONTEXT when answering the QUESTION.\n",
        "\n",
        "QUESTION: {question}\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\"\"\".strip()\n",
        "\n",
        "    context = \"\"\n",
        "\n",
        "    for doc in search_results:\n",
        "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
        "\n",
        "    prompt = prompt_template.format(question=query, context=context).strip()\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvAA1UM1tjoE"
      },
      "outputs": [],
      "source": [
        "def llm(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model='gpt-4o',\n",
        "        messages=[\n",
        "            {\n",
        "                'role': 'user',\n",
        "                'content': prompt\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNtv-b-8V3X_"
      },
      "source": [
        "### ---trial run before build RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I08cSMa7tBCW"
      },
      "outputs": [],
      "source": [
        "# num_results = 2\n",
        "\n",
        "query = 'How do I run kafka?'\n",
        "search_results = search(query)\n",
        "prompt = build_prompt(query, search_results)\n",
        "answer = llm(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvQs7hL9Tiq-",
        "outputId": "1f042712-6318-4e53-db69-a0d55794f94b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java',\n",
              "  'section': 'Module 6: streaming with kafka',\n",
              "  'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\",\n",
              "  'section': 'Module 6: streaming with kafka',\n",
              "  'question': 'Module “kafka” not found when trying to run producer.py',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': \"Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\",\n",
              "  'section': 'Workshop 1 - dlthub',\n",
              "  'question': 'How do I install the necessary dependencies to run the code?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'Run this command in terminal in the same directory (/docker/spark):\\nchmod +x build.sh',\n",
              "  'section': 'Module 6: streaming with kafka',\n",
              "  'question': 'Python Kafka: ./build.sh: Permission denied Error',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'According to https://github.com/dpkp/kafka-python/\\n“DUE TO ISSUES WITH RELEASES, IT IS SUGGESTED TO USE https://github.com/wbarnha/kafka-python-ng FOR THE TIME BEING”\\nUse pip install kafka-python-ng instead',\n",
              "  'section': 'Project',\n",
              "  'question': 'How to fix the error \"ModuleNotFoundError: No module named \\'kafka.vendor.six.moves\\'\"?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.',\n",
              "  'section': 'Module 6: streaming with kafka',\n",
              "  'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'Start a new terminal\\nRun: docker ps\\nCopy the CONTAINER ID of the spark-master container\\nRun: docker exec -it <spark_master_container_id> bash\\nRun: cat logs/spark-master.out\\nCheck for the log when the error happened\\nGoogle the error message from there',\n",
              "  'section': 'Module 6: streaming with kafka',\n",
              "  'question': 'Python Kafka: ./spark-submit.sh streaming.py - How to check why Spark master connection fails',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'You can check the version of your local spark using spark-submit --version. In the build.sh file of the Python folder, make sure that SPARK_VERSION matches your local version. Similarly, make sure the pyspark you pip installed also matches this version.',\n",
              "  'section': 'Module 6: streaming with kafka',\n",
              "  'question': 'How do I check compatibility of local and container Spark versions?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\nfastavro: pip install fastavro\\nAbhirup Ghosh\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.',\n",
              "  'section': 'Module 6: streaming with kafka',\n",
              "  'question': 'Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/',\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'How do I use Git / GitHub for this course?',\n",
              "  'course': 'data-engineering-zoomcamp'}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "search_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2tYD7oVt7cw",
        "outputId": "83fb7d02-598d-474d-ac40-10f181e14273"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To run Kafka, you can execute the following command in the project directory:\\n\\n```bash\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n```\\n\\nReplace `<jar_name>` with the appropriate jar file name in your project.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "az5rhUyUAjIP"
      },
      "outputs": [],
      "source": [
        "# num_results = 2\n",
        "\n",
        "query = 'the course has alreaady started, can I still enroll?'\n",
        "search_results = search(query)\n",
        "prompt = build_prompt(query, search_results)\n",
        "answer = llm(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSH3u6hmTwWx",
        "outputId": "c9e23bf7-36f8-48d4-f13d-4ff8b05c0d10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - Can I still join the course after the start date?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - Can I follow the course after it finishes?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - When will the course start?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - What can I do before the course starts?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'How can we contribute to the course?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.',\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - Can I get support if I take the course in the self-paced mode?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites',\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - What are the prerequisites for this course?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Certificate - Can I follow the course in a self-paced mode and get a certificate?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'Yes, for simplicity (of troubleshooting against the recorded videos) and stability. [source]\\nBut Python 3.10 and 3.11 should work fine.',\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Environment - Is Python 3.9 still the recommended version to use in 2024?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
              "  'course': 'data-engineering-zoomcamp'}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "search_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8MdWHMyAlnU",
        "outputId": "fd6ed77c-5cff-4229-e20e-a4b8effb2060"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Yes, you can still enroll in the course even if it has already started. You're eligible to submit the homework assignments. However, be mindful of the deadlines for the final projects and try not to leave everything for the last minute.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0co8sg_WSfRU"
      },
      "outputs": [],
      "source": [
        "# change num_results to 10\n",
        "\n",
        "query = 'How do I run kafka?'\n",
        "search_results = search(query)\n",
        "prompt = build_prompt(query, search_results)\n",
        "answer = llm(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZb-LdO-TH14",
        "outputId": "5e0cdae2-7265-40d9-c5bb-4914bd41d07e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To run Kafka, if you are using Java, you need to execute the following command in the project directory:\\n\\n```bash\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n```\\n\\nIf you are using Python and facing a \"Module not found\" error, it\\'s recommended to create a virtual environment and run the `requirements.txt` file and the Python files within that environment. Here\\'s how you can set up and activate the virtual environment:\\n\\n1. Create a virtual environment (run only once):\\n   ```bash\\n   python -m venv env\\n   ```\\n\\n2. Activate the virtual environment:\\n   - On MacOS or Linux:\\n     ```bash\\n     source env/bin/activate\\n     ```\\n   - On Windows:\\n     ```bash\\n     env\\\\Scripts\\\\activate\\n     ```\\n\\n3. Install the necessary packages:\\n   ```bash\\n   pip install -r ../requirements.txt\\n   ```\\n\\nTo deactivate the virtual environment, simply run:\\n\\n```bash\\ndeactivate\\n```\\n\\nPlease make sure your Docker images are all up and running before proceeding.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoZPX7YCWL_8"
      },
      "source": [
        "### ---trial run ends here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgEl_4ncULvA"
      },
      "source": [
        "### def RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "comzNFiBUNZg"
      },
      "outputs": [],
      "source": [
        "# num_results = 10, line 14\n",
        "\n",
        "query = 'How do I run kafka?' # move query out of the def rag(query)\n",
        "\n",
        "def rag(query):\n",
        "    search_results = search(query)  # search can be changed to other search engine\n",
        "    prompt = build_prompt(query, search_results)\n",
        "    answer = llm(prompt)  # llm can be changed to other llm\n",
        "\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "bzCVmswSUeoM",
        "outputId": "361f8e9e-28b4-4892-e8bc-ef95a468bc68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To run Kafka, navigate to your project directory and execute the following command in the terminal:\\n\\n```shell\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n```\\n\\nThis command is used to run the Java Kafka producer, consumer, kstreams, etc.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "rag(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "syPo0yAKUuM9",
        "outputId": "b14fe497-4c75-4427-b18e-1bbc68466793"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, you can still enroll in the course even if it has already started. You are eligible to submit the homework, but be sure to comply with the deadlines for submitting final projects, so avoid leaving everything to the last minute.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "rag('the course has alreaady started, can I still enroll?')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VdSkAUwZxVB"
      },
      "source": [
        "### ---examine serach_reasults and answer in rag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjDsjtHiZarL",
        "outputId": "2aa99dad-7423-4c45-9f31-721c93a00710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search Results:\n",
            "Result 1:\n",
            "Q: Java Kafka: How to run producer/consumer/kstreams/etc in terminal\n",
            "A: In the project directory, run:\n",
            "java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org...\n",
            "\n",
            "Result 2:\n",
            "Q: Module “kafka” not found when trying to run producer.py\n",
            "A: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in ...\n",
            "\n",
            "Result 3:\n",
            "Q: How do I install the necessary dependencies to run the code?\n",
            "A: Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do thi...\n",
            "\n",
            "Result 4:\n",
            "Q: Python Kafka: ./build.sh: Permission denied Error\n",
            "A: Run this command in terminal in the same directory (/docker/spark):\n",
            "chmod +x build.sh...\n",
            "\n",
            "Result 5:\n",
            "Q: How to fix the error \"ModuleNotFoundError: No module named 'kafka.vendor.six.moves'\"?\n",
            "A: According to https://github.com/dpkp/kafka-python/\n",
            "“DUE TO ISSUES WITH RELEASES, IT IS SUGGESTED TO ...\n",
            "\n",
            "Result 6:\n",
            "Q: kafka.errors.NoBrokersAvailable: NoBrokersAvailable\n",
            "A: If you have this error, it most likely that your kafka broker docker container is not working.\n",
            "Use d...\n",
            "\n",
            "Result 7:\n",
            "Q: Python Kafka: ./spark-submit.sh streaming.py - How to check why Spark master connection fails\n",
            "A: Start a new terminal\n",
            "Run: docker ps\n",
            "Copy the CONTAINER ID of the spark-master container\n",
            "Run: docker ...\n",
            "\n",
            "Result 8:\n",
            "Q: How do I check compatibility of local and container Spark versions?\n",
            "A: You can check the version of your local spark using spark-submit --version. In the build.sh file of ...\n",
            "\n",
            "Result 9:\n",
            "Q: Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py\n",
            "A: confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka...\n",
            "\n",
            "Result 10:\n",
            "Q: How do I use Git / GitHub for this course?\n",
            "A: After you create a GitHub account, you should clone the course repo to your local machine using the ...\n",
            "\n",
            "Final Answer: To run Kafka using Java, navigate to your project directory and execute the following command in the terminal:\n",
            "\n",
            "```bash\n",
            "java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\n",
            "```\n",
            "\n",
            "Please replace `<jar_name>` with the actual name of your JAR file.\n"
          ]
        }
      ],
      "source": [
        "# num_results = 10, line 14\n",
        "\n",
        "def rag(query):\n",
        "    search_results = search(query)\n",
        "\n",
        "    print(\"Search Results:\")\n",
        "    for i, result in enumerate(search_results, 1):\n",
        "        print(f\"Result {i}:\")\n",
        "        print(f\"Q: {result['question']}\")\n",
        "        print(f\"A: {result['text'][:100]}...\")  # Print only the first 100 characters of the answer.\n",
        "        print()\n",
        "\n",
        "    prompt = build_prompt(query, search_results)\n",
        "    answer = llm(prompt)\n",
        "\n",
        "    return answer\n",
        "\n",
        "# call rag function\n",
        "result = rag(query)\n",
        "print(\"Final Answer:\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlOCSxeRaTOu",
        "outputId": "666d9bcc-0cc5-43c9-e81d-a56394fd646c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Concise Search Results:\n",
            "Result 1:\n",
            "Q: Java Kafka: How to run producer/consumer/kstreams/etc in terminal\n",
            "A: In the project directory, run:\n",
            "java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org...\n",
            "\n",
            "Result 2:\n",
            "Q: Module “kafka” not found when trying to run producer.py\n",
            "A: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in ...\n",
            "\n",
            "Result 3:\n",
            "Q: How do I install the necessary dependencies to run the code?\n",
            "A: Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do thi...\n",
            "\n",
            "Result 4:\n",
            "Q: Python Kafka: ./build.sh: Permission denied Error\n",
            "A: Run this command in terminal in the same directory (/docker/spark):\n",
            "chmod +x build.sh...\n",
            "\n",
            "Result 5:\n",
            "Q: How to fix the error \"ModuleNotFoundError: No module named 'kafka.vendor.six.moves'\"?\n",
            "A: According to https://github.com/dpkp/kafka-python/\n",
            "“DUE TO ISSUES WITH RELEASES, IT IS SUGGESTED TO ...\n",
            "\n",
            "Result 6:\n",
            "Q: kafka.errors.NoBrokersAvailable: NoBrokersAvailable\n",
            "A: If you have this error, it most likely that your kafka broker docker container is not working.\n",
            "Use d...\n",
            "\n",
            "Result 7:\n",
            "Q: Python Kafka: ./spark-submit.sh streaming.py - How to check why Spark master connection fails\n",
            "A: Start a new terminal\n",
            "Run: docker ps\n",
            "Copy the CONTAINER ID of the spark-master container\n",
            "Run: docker ...\n",
            "\n",
            "Result 8:\n",
            "Q: How do I check compatibility of local and container Spark versions?\n",
            "A: You can check the version of your local spark using spark-submit --version. In the build.sh file of ...\n",
            "\n",
            "Result 9:\n",
            "Q: Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py\n",
            "A: confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka...\n",
            "\n",
            "Result 10:\n",
            "Q: How do I use Git / GitHub for this course?\n",
            "A: After you create a GitHub account, you should clone the course repo to your local machine using the ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query = 'How do I run kafka?'\n",
        "search_results = search(query)\n",
        "\n",
        "print(\"\\nConcise Search Results:\")\n",
        "for i, result in enumerate(search_results, 1):\n",
        "    print(f\"Result {i}:\")\n",
        "    print(f\"Q: {result['question']}\")\n",
        "    print(f\"A: {result['text'][:100]}...\")  # 只打印答案的前100個字符\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu1RDafbZdK3",
        "outputId": "a0bf6bba-e4dd-4c38-b185-c6a36fd735cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search Results:\n",
            "Result 1:\n",
            "Q: Java Kafka: How to run producer/consumer/kstreams/etc in terminal\n",
            "A: In the project directory, run:\n",
            "java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org...\n",
            "\n",
            "Result 2:\n",
            "Q: Module “kafka” not found when trying to run producer.py\n",
            "A: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in ...\n",
            "\n",
            "Result 3:\n",
            "Q: How do I install the necessary dependencies to run the code?\n",
            "A: Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do thi...\n",
            "\n",
            "Result 4:\n",
            "Q: Python Kafka: ./build.sh: Permission denied Error\n",
            "A: Run this command in terminal in the same directory (/docker/spark):\n",
            "chmod +x build.sh...\n",
            "\n",
            "Result 5:\n",
            "Q: How to fix the error \"ModuleNotFoundError: No module named 'kafka.vendor.six.moves'\"?\n",
            "A: According to https://github.com/dpkp/kafka-python/\n",
            "“DUE TO ISSUES WITH RELEASES, IT IS SUGGESTED TO ...\n",
            "\n",
            "Result 6:\n",
            "Q: kafka.errors.NoBrokersAvailable: NoBrokersAvailable\n",
            "A: If you have this error, it most likely that your kafka broker docker container is not working.\n",
            "Use d...\n",
            "\n",
            "Result 7:\n",
            "Q: Python Kafka: ./spark-submit.sh streaming.py - How to check why Spark master connection fails\n",
            "A: Start a new terminal\n",
            "Run: docker ps\n",
            "Copy the CONTAINER ID of the spark-master container\n",
            "Run: docker ...\n",
            "\n",
            "Result 8:\n",
            "Q: How do I check compatibility of local and container Spark versions?\n",
            "A: You can check the version of your local spark using spark-submit --version. In the build.sh file of ...\n",
            "\n",
            "Result 9:\n",
            "Q: Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py\n",
            "A: confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka...\n",
            "\n",
            "Result 10:\n",
            "Q: How do I use Git / GitHub for this course?\n",
            "A: After you create a GitHub account, you should clone the course repo to your local machine using the ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 或者直接調用 rag 函數\n",
        "result = rag(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_6jztpVa9jo"
      },
      "source": [
        "### ---examine serach_reasults and answer in rag ends here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbylPlg3zE_T"
      },
      "source": [
        "# 1.6 Elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1nU_R75yxq8",
        "outputId": "7ffba47d-df17-4406-b7f5-a916b6a75cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.10/dist-packages (8.15.1)\n",
            "Requirement already satisfied: elastic-transport<9,>=8.13 in /usr/local/lib/python3.10/dist-packages (from elasticsearch) (8.15.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch) (2.2.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "from elasticsearch import Elasticsearch\n",
        "from google.colab import userdata\n",
        "from getpass import getpass\n",
        "\n",
        "# 嘗試從 Colab 的環境變數中取得 Elastic Cloud ID 和 API Key\n",
        "ELASTIC_CLOUD_ID = userdata.get('ELASTIC_CLOUD_ID')\n",
        "ELASTIC_API_KEY = userdata.get('ELASTIC_API_KEY')\n",
        "\n",
        "# 如果環境變數中沒有找到，則請求用戶輸入\n",
        "if not ELASTIC_CLOUD_ID:\n",
        "    ELASTIC_CLOUD_ID = getpass(\"輸入 Elastic Cloud ID: \")\n",
        "\n",
        "if not ELASTIC_API_KEY:\n",
        "    ELASTIC_API_KEY = getpass(\"輸入 Elastic Api Key: \")\n",
        "\n",
        "try:\n",
        "    # Create the client\n",
        "    es_client = Elasticsearch(\n",
        "        cloud_id=ELASTIC_CLOUD_ID,\n",
        "        api_key=ELASTIC_API_KEY,\n",
        "        timeout=60  # 增加超時時間\n",
        "    )\n",
        "\n",
        "    # Check connection\n",
        "    if es_client.ping():\n",
        "        print('Successfully connected to Elasticsearch')\n",
        "        print(es_client.info())\n",
        "    else:\n",
        "        print('Could not connect to Elasticsearch')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Connection error: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKErszhvJKsz",
        "outputId": "0b8731ba-a2ff-4c3b-ffe4-7a147c4151c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-98a0701a3ba1>:20: DeprecationWarning: The 'timeout' parameter is deprecated in favor of 'request_timeout'\n",
            "  es_client = Elasticsearch(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully connected to Elasticsearch\n",
            "{'name': 'instance-0000000001', 'cluster_name': 'bd5c04e72b0c4673b4cbd3db98fdb86b', 'cluster_uuid': 'K11-nm1NQeu_GpxDE5TTJg', 'version': {'number': '8.14.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': 'd55f984299e0e88dee72ebd8255f7ff130859ad0', 'build_date': '2024-07-07T22:04:49.882652950Z', 'build_snapshot': False, 'lucene_version': '9.10.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccWZnQOFSOZZ",
        "outputId": "af11afd4-e50e-4309-8896-1dc59d894bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
              " 'section': 'General course-related questions',\n",
              " 'question': 'Course - When will the course start?',\n",
              " 'course': 'data-engineering-zoomcamp'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es_client.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1iwMr390DiJ",
        "outputId": "ef9238d7-67c7-4cea-bd40-5c0ae981548d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'name': 'instance-0000000001', 'cluster_name': 'bd5c04e72b0c4673b4cbd3db98fdb86b', 'cluster_uuid': 'K11-nm1NQeu_GpxDE5TTJg', 'version': {'number': '8.14.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': 'd55f984299e0e88dee72ebd8255f7ff130859ad0', 'build_date': '2024-07-07T22:04:49.882652950Z', 'build_snapshot': False, 'lucene_version': '9.10.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3xDADGC3O3c"
      },
      "source": [
        "### Index settings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24fKJLtr4KI8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "3ca73ffc-782c-46a0-a2ae-5dcadf0708e9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "BadRequestError(400, 'resource_already_exists_exception', 'index [course-questions/E5SZf1OnSsy0mHa7sOxgAA] already exists')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-3b59891c9af1>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mindex_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"course-questions\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mes_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# # 創建索引\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/elasticsearch/_sync/client/utils.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m  \u001b[0;31m# type: ignore[return-value]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/elasticsearch/_sync/client/indices.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, index, aliases, error_trace, filter_path, human, mappings, master_timeout, pretty, settings, timeout, wait_for_active_shards, body)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m__body\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0m__headers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content-type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         return self.perform_request(  # type: ignore[return-value]\n\u001b[0m\u001b[1;32m    546\u001b[0m             \u001b[0;34m\"PUT\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0m__path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/elasticsearch/_sync/client/_base.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;31m# Use the internal clients .perform_request() implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;31m# so we take advantage of their transport options.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         return self._client.perform_request(\n\u001b[0m\u001b[1;32m    424\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/elasticsearch/_sync/client/_base.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mpath_parts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_parts\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         ) as otel_span:\n\u001b[0;32m--> 271\u001b[0;31m             response = self._perform_request(\n\u001b[0m\u001b[1;32m    272\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/elasticsearch/_sync/client/_base.py\u001b[0m in \u001b[0;36m_perform_request\u001b[0;34m(self, method, path, params, headers, body, otel_span)\u001b[0m\n\u001b[1;32m    350\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             raise HTTP_EXCEPTIONS.get(meta.status, ApiError)(\n\u001b[0m\u001b[1;32m    353\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresp_body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             )\n",
            "\u001b[0;31mBadRequestError\u001b[0m: BadRequestError(400, 'resource_already_exists_exception', 'index [course-questions/E5SZf1OnSsy0mHa7sOxgAA] already exists')"
          ]
        }
      ],
      "source": [
        "# 定義索引設置\n",
        "index_settings = {\n",
        "    \"settings\": {\n",
        "        \"number_of_shards\": 1,\n",
        "        \"number_of_replicas\": 0\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"text\": {\"type\": \"text\"},\n",
        "            \"section\": {\"type\": \"text\"},\n",
        "            \"question\": {\"type\": \"text\"},\n",
        "            \"course\": {\"type\": \"keyword\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "index_name = \"course-questions\"\n",
        "\n",
        "es_client.indices.create(index=index_name, body=index_settings)\n",
        "\n",
        "# # 創建索引\n",
        "# result = es_client.indices.create(index=index_name, body=index_settings)\n",
        "# print(f\"創建索引結果: {result}\")\n",
        "\n",
        "# # 驗證索引創建是否成功\n",
        "# if result.get('acknowledged'):\n",
        "#     print(\"索引創建成功！\")\n",
        "# else:\n",
        "#     print(\"索引創建失敗。\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    exists = es_client.indices.exists(index=\"course-questions\")\n",
        "    print(f\"索引檢查結果: {'已存在' if exists else '不存在'}\")\n",
        "\n",
        "    if not exists:\n",
        "        result = es_client.indices.create(index=\"course-questions\", body=index_settings)\n",
        "        print(f\"索引創建狀態: {'成功' if result.get('acknowledged') else '失敗'}\")\n",
        "except Exception as e:\n",
        "    print(f\"錯誤: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWAxyc6o192D",
        "outputId": "839ed3d3-ec1f-47e4-9d0d-3e744f5a84ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "索引檢查結果: 已存在\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrj9G9C81QRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e738ffd3-4816-4a97-b2a9-b127cb0a0433"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
              " 'section': 'General course-related questions',\n",
              " 'question': 'Course - When will the course start?',\n",
              " 'course': 'data-engineering-zoomcamp'}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2SGfYKZ1peJ"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-ZU8UiN1eZw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cd1b5f5fd0f4425e8d431b21d69375e1",
            "e5f6536e36e2401f8d34c877f9072884",
            "c9161e6652074771b043fc56fd9fcf0c",
            "e255ec256bba4e8281314f740d50c115",
            "4ab66250ed964d48a0f4c88a0baa55cf",
            "ae13c8d6b6f141aa904abdf5adefdc4c",
            "725c23991b49421daf6c61ca542c58a7",
            "50db9ae15d784bf39da53dbddd874895",
            "178a7f466fd74a42876f0225dc64f472",
            "0c26c5af2817491583195731d2d5e47e",
            "ae89b5aef7a44c208776db604865230d"
          ]
        },
        "outputId": "b2d9c2bc-033e-448e-e6ab-636eb880ed7b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/948 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd1b5f5fd0f4425e8d431b21d69375e1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "for doc in tqdm(documents):\n",
        "    es_client.index(index=index_name, document=doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhUKv5ZI3QXa"
      },
      "source": [
        "### Query:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jgpF6fp53acv",
        "outputId": "0b5b85f7-e113-4044-85ab-876ca88b691c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How do I run kafka?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_gUoxi72o4y"
      },
      "outputs": [],
      "source": [
        "query = 'I just discover the course. Can I still join it?'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCvy60AC2vtR"
      },
      "outputs": [],
      "source": [
        "search_query = {\n",
        "    \"size\": 5,  # we will only get 5 answers\n",
        "    \"query\": {\n",
        "        \"bool\": {\n",
        "            \"must\": {\n",
        "                \"multi_match\": {\n",
        "                    \"query\": query,\n",
        "                    \"fields\": [\"question^3\", \"text\", \"section\"],  # question^3: question is 3 times more important than text or section\n",
        "                    \"type\": \"best_fields\"\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"term\": {\n",
        "                    \"course\": \"data-engineering-zoomcamp\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcDDU6o264YT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae89e796-24eb-4a49-9898-d2e1533a6001"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'took': 24, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 405, 'relation': 'eq'}, 'max_score': 72.849266, 'hits': [{'_index': 'course-questions', '_id': 'ASTc_JIByjD8izo6PZw9', '_score': 72.849266, '_source': {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\", 'section': 'General course-related questions', 'question': 'Course - Can I still join the course after the start date?', 'course': 'data-engineering-zoomcamp'}}, {'_index': 'course-questions', '_id': 'BiTc_JIByjD8izo6QJyv', '_score': 54.057133, '_source': {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.', 'section': 'General course-related questions', 'question': 'Course - Can I follow the course after it finishes?', 'course': 'data-engineering-zoomcamp'}}, {'_index': 'course-questions', '_id': 'AyTc_JIByjD8izo6Ppyb', '_score': 43.841484, '_source': {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.', 'section': 'General course-related questions', 'question': 'Course - What can I do before the course starts?', 'course': 'data-engineering-zoomcamp'}}, {'_index': 'course-questions', '_id': 'ByTc_JIByjD8izo6QZxe', '_score': 42.651314, '_source': {'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.', 'section': 'General course-related questions', 'question': 'Course - Can I get support if I take the course in the self-paced mode?', 'course': 'data-engineering-zoomcamp'}}, {'_index': 'course-questions', '_id': 'AiTc_JIByjD8izo6PZzs', '_score': 35.820084, '_source': {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\", 'section': 'General course-related questions', 'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?', 'course': 'data-engineering-zoomcamp'}}]}})"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "es_client.search(index=index_name, body=search_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meF4jbKb69Ki"
      },
      "outputs": [],
      "source": [
        "response = es_client.search(index=index_name, body=search_query)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWKDfxtR4rFw",
        "outputId": "b76ea058-ad0b-4431-949d-04fac06e622c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'took': 4, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 405, 'relation': 'eq'}, 'max_score': 72.849266, 'hits': [{'_index': 'course-questions', '_id': 'ASTc_JIByjD8izo6PZw9', '_score': 72.849266, '_source': {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\", 'section': 'General course-related questions', 'question': 'Course - Can I still join the course after the start date?', 'course': 'data-engineering-zoomcamp'}}, {'_index': 'course-questions', '_id': 'BiTc_JIByjD8izo6QJyv', '_score': 54.057133, '_source': {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.', 'section': 'General course-related questions', 'question': 'Course - Can I follow the course after it finishes?', 'course': 'data-engineering-zoomcamp'}}, {'_index': 'course-questions', '_id': 'AyTc_JIByjD8izo6Ppyb', '_score': 43.841484, '_source': {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.', 'section': 'General course-related questions', 'question': 'Course - What can I do before the course starts?', 'course': 'data-engineering-zoomcamp'}}, {'_index': 'course-questions', '_id': 'ByTc_JIByjD8izo6QZxe', '_score': 42.651314, '_source': {'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.', 'section': 'General course-related questions', 'question': 'Course - Can I get support if I take the course in the self-paced mode?', 'course': 'data-engineering-zoomcamp'}}, {'_index': 'course-questions', '_id': 'AiTc_JIByjD8izo6PZzs', '_score': 35.820084, '_source': {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\", 'section': 'General course-related questions', 'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?', 'course': 'data-engineering-zoomcamp'}}]}})"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response ['hits']\n",
        "\n",
        "# ['hits'] outputs' include metadata: {'total': {'value': 405, 'relation': 'eq'}, 'max_score': 72.849266,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzIaSvZg5U7Q",
        "outputId": "3b436ea9-c67e-41ef-9f6f-d84979a47cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'total': {'value': 405, 'relation': 'eq'},\n",
              " 'max_score': 72.849266,\n",
              " 'hits': [{'_index': 'course-questions',\n",
              "   '_id': 'ASTc_JIByjD8izo6PZw9',\n",
              "   '_score': 72.849266,\n",
              "   '_source': {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
              "    'section': 'General course-related questions',\n",
              "    'question': 'Course - Can I still join the course after the start date?',\n",
              "    'course': 'data-engineering-zoomcamp'}},\n",
              "  {'_index': 'course-questions',\n",
              "   '_id': 'BiTc_JIByjD8izo6QJyv',\n",
              "   '_score': 54.057133,\n",
              "   '_source': {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
              "    'section': 'General course-related questions',\n",
              "    'question': 'Course - Can I follow the course after it finishes?',\n",
              "    'course': 'data-engineering-zoomcamp'}},\n",
              "  {'_index': 'course-questions',\n",
              "   '_id': 'AyTc_JIByjD8izo6Ppyb',\n",
              "   '_score': 43.841484,\n",
              "   '_source': {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
              "    'section': 'General course-related questions',\n",
              "    'question': 'Course - What can I do before the course starts?',\n",
              "    'course': 'data-engineering-zoomcamp'}},\n",
              "  {'_index': 'course-questions',\n",
              "   '_id': 'ByTc_JIByjD8izo6QZxe',\n",
              "   '_score': 42.651314,\n",
              "   '_source': {'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.',\n",
              "    'section': 'General course-related questions',\n",
              "    'question': 'Course - Can I get support if I take the course in the self-paced mode?',\n",
              "    'course': 'data-engineering-zoomcamp'}},\n",
              "  {'_index': 'course-questions',\n",
              "   '_id': 'AiTc_JIByjD8izo6PZzs',\n",
              "   '_score': 35.820084,\n",
              "   '_source': {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
              "    'section': 'General course-related questions',\n",
              "    'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
              "    'course': 'data-engineering-zoomcamp'}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response ['hits']['hits']\n",
        "\n",
        "# ['hits'['hits'] outputs' don't include metadata: {'total': {'value': 405, 'relation': 'eq'}, 'max_score': 72.849266,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqln8n1Y5XrB",
        "outputId": "dc41caa8-42ab-473d-cafe-4289bf9fbcc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'_index': 'course-questions',\n",
              "  '_id': 'ASTc_JIByjD8izo6PZw9',\n",
              "  '_score': 72.849266,\n",
              "  '_source': {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
              "   'section': 'General course-related questions',\n",
              "   'question': 'Course - Can I still join the course after the start date?',\n",
              "   'course': 'data-engineering-zoomcamp'}},\n",
              " {'_index': 'course-questions',\n",
              "  '_id': 'BiTc_JIByjD8izo6QJyv',\n",
              "  '_score': 54.057133,\n",
              "  '_source': {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
              "   'section': 'General course-related questions',\n",
              "   'question': 'Course - Can I follow the course after it finishes?',\n",
              "   'course': 'data-engineering-zoomcamp'}},\n",
              " {'_index': 'course-questions',\n",
              "  '_id': 'AyTc_JIByjD8izo6Ppyb',\n",
              "  '_score': 43.841484,\n",
              "  '_source': {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
              "   'section': 'General course-related questions',\n",
              "   'question': 'Course - What can I do before the course starts?',\n",
              "   'course': 'data-engineering-zoomcamp'}},\n",
              " {'_index': 'course-questions',\n",
              "  '_id': 'ByTc_JIByjD8izo6QZxe',\n",
              "  '_score': 42.651314,\n",
              "  '_source': {'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.',\n",
              "   'section': 'General course-related questions',\n",
              "   'question': 'Course - Can I get support if I take the course in the self-paced mode?',\n",
              "   'course': 'data-engineering-zoomcamp'}},\n",
              " {'_index': 'course-questions',\n",
              "  '_id': 'AiTc_JIByjD8izo6PZzs',\n",
              "  '_score': 35.820084,\n",
              "  '_source': {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
              "   'section': 'General course-related questions',\n",
              "   'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
              "   'course': 'data-engineering-zoomcamp'}}]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to go into the source\n",
        "result_docs = []\n",
        "\n",
        "for hit in response['hits']['hits']:\n",
        "    result_docs.append(hit['_source'])\n",
        "\n",
        "# # Suppose hit is a dictionary structured like this:\n",
        "# hit = {\n",
        "#     '_index': 'course-questions',     # Other data\n",
        "#     '_id': 'ASTc_JIByjD8izo6PZw9',   # Other data\n",
        "#     '_score': 72.849266,              # Other data\n",
        "#     '_source': {                      # <- The data we need is here\n",
        "#         'text': \"Yes, even if...\",\n",
        "#         'section': \"General course-related questions\",\n",
        "#         'question': \"Course - Can I still...\",\n",
        "#         'course': \"data-engineering-zoomcamp\"\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# # hit['_source'] extracts all the data inside _source:\n",
        "# source_data = hit['_source']\n",
        "# # source_data now contains:\n",
        "# {\n",
        "#     'text': \"Yes, even if...\",\n",
        "#     'section': \"General course-related questions\",\n",
        "#     'question': \"Course - Can I still...\",\n",
        "#     'course': \"data-engineering-zoomcamp\"\n",
        "# }\n",
        "\n",
        "# # So when we write:\n",
        "# result_docs.append(hit['_source'])\n",
        "\n",
        "# # It is equivalent to:\n",
        "# result_docs.append({\n",
        "#     'text': \"Yes, even if...\",\n",
        "#     'section': \"General course-related questions\",\n",
        "#     'question': \"Course - Can I still...\",\n",
        "#     'course': \"data-engineering-zoomcamp\"\n",
        "# })\n"
      ],
      "metadata": {
        "id": "J9Es8NZZ5gPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create an empty list\n",
        "# fruits = []\n",
        "# print(\"Initial empty list:\", fruits)  # Output: []\n",
        "\n",
        "# # Add a single fruit using append\n",
        "# fruits.append(\"Apple\")\n",
        "# print(\"After adding Apple:\", fruits)  # Output: ['Apple']\n",
        "\n",
        "# # Add another fruit\n",
        "# fruits.append(\"Banana\")\n",
        "# print(\"After adding Banana:\", fruits)  # Output: ['Apple', 'Banana']\n",
        "\n",
        "# # Add one more fruit\n",
        "# fruits.append(\"Orange\")\n",
        "# print(\"After adding Orange:\", fruits)  # Output: ['Apple', 'Banana', 'Orange']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbfLzCa-8M3M",
        "outputId": "69b455a8-b982-4ee0-9f7d-6c2954968cc8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial empty list: []\n",
            "After adding Apple: ['Apple']\n",
            "After adding Banana: ['Apple', 'Banana']\n",
            "After adding Orange: ['Apple', 'Banana', 'Orange']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhKG1RjI8LYG",
        "outputId": "8d0d4863-da64-45a8-ffc4-f01814e3bf53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - Can I still join the course after the start date?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - Can I follow the course after it finishes?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - What can I do before the course starts?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.',\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - Can I get support if I take the course in the self-paced mode?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
              "  'course': 'data-engineering-zoomcamp'}]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Put search function together and test"
      ],
      "metadata": {
        "id": "xHPdsHRU_nu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def elastic_search(query):\n",
        "\n",
        "  search_query = {\n",
        "      \"size\": 5,  # we will only get 5 answers\n",
        "      \"query\": {\n",
        "          \"bool\": {\n",
        "              \"must\": {\n",
        "                  \"multi_match\": {\n",
        "                      \"query\": query,\n",
        "                      \"fields\": [\"question^3\", \"text\", \"section\"],  # question^3: question is 3 times more important than text or section\n",
        "                      \"type\": \"best_fields\"\n",
        "                  }\n",
        "              },\n",
        "              \"filter\": {\n",
        "                  \"term\": {\n",
        "                      \"course\": \"data-engineering-zoomcamp\"\n",
        "                  }\n",
        "              }\n",
        "          }\n",
        "      }\n",
        "  }\n",
        "\n",
        "  response = es_client.search(index=index_name, body=search_query)\n",
        "\n",
        "  result_docs = []\n",
        "\n",
        "  for hit in response['hits']['hits']:\n",
        "      result_docs.append(hit['_source'])\n",
        "\n",
        "  return result_docs"
      ],
      "metadata": {
        "id": "03H0ZaZr_GE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elastic_search(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjVmCI-M_xxJ",
        "outputId": "80bab808-6a6f-4a3c-b43d-ce0baaa33c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - Can I still join the course after the start date?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - Can I follow the course after it finishes?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - What can I do before the course starts?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.',\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - Can I get support if I take the course in the self-paced mode?',\n",
              "  'course': 'data-engineering-zoomcamp'},\n",
              " {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
              "  'section': 'General course-related questions',\n",
              "  'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
              "  'course': 'data-engineering-zoomcamp'}]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # Put RAG and search function together and test"
      ],
      "metadata": {
        "id": "QoDi29aWARV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def elastic_search(query):\n",
        "\n",
        "  search_query = {\n",
        "      \"size\": 5,  # we will only get 5 answers\n",
        "      \"query\": {\n",
        "          \"bool\": {\n",
        "              \"must\": {\n",
        "                  \"multi_match\": {\n",
        "                      \"query\": query,\n",
        "                      \"fields\": [\"question^3\", \"text\", \"section\"],  # question^3: question is 3 times more important than text or section\n",
        "                      \"type\": \"best_fields\"\n",
        "                  }\n",
        "              },\n",
        "              \"filter\": {\n",
        "                  \"term\": {\n",
        "                      \"course\": \"data-engineering-zoomcamp\"\n",
        "                  }\n",
        "              }\n",
        "          }\n",
        "      }\n",
        "  }\n",
        "\n",
        "  response = es_client.search(index=index_name, body=search_query)\n",
        "\n",
        "  result_docs = []\n",
        "\n",
        "  for hit in response['hits']['hits']:\n",
        "      result_docs.append(hit['_source'])\n",
        "\n",
        "  return result_docs"
      ],
      "metadata": {
        "id": "vzIki6VyALyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rag(query):\n",
        "    search_results = elastic_search(query)  # search can be changed to other search engine\n",
        "    prompt = build_prompt(query, search_results)\n",
        "    answer = llm(prompt)  # llm can be changed to other llm\n",
        "    return answer"
      ],
      "metadata": {
        "id": "dFfF-BRCAX79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "93b74865-a9e8-4b41-cc8e-0c6a7dee9585",
        "id": "boYXdMn2ALyT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Yes, you can still join the course even if you've just discovered it. You are eligible to submit the homeworks even without registering. However, keep in mind that there will be deadlines for turning in the final projects, so don't procrastinate.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd1b5f5fd0f4425e8d431b21d69375e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5f6536e36e2401f8d34c877f9072884",
              "IPY_MODEL_c9161e6652074771b043fc56fd9fcf0c",
              "IPY_MODEL_e255ec256bba4e8281314f740d50c115"
            ],
            "layout": "IPY_MODEL_4ab66250ed964d48a0f4c88a0baa55cf"
          }
        },
        "e5f6536e36e2401f8d34c877f9072884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae13c8d6b6f141aa904abdf5adefdc4c",
            "placeholder": "​",
            "style": "IPY_MODEL_725c23991b49421daf6c61ca542c58a7",
            "value": "100%"
          }
        },
        "c9161e6652074771b043fc56fd9fcf0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50db9ae15d784bf39da53dbddd874895",
            "max": 948,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_178a7f466fd74a42876f0225dc64f472",
            "value": 948
          }
        },
        "e255ec256bba4e8281314f740d50c115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c26c5af2817491583195731d2d5e47e",
            "placeholder": "​",
            "style": "IPY_MODEL_ae89b5aef7a44c208776db604865230d",
            "value": " 948/948 [02:46&lt;00:00,  5.71it/s]"
          }
        },
        "4ab66250ed964d48a0f4c88a0baa55cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae13c8d6b6f141aa904abdf5adefdc4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "725c23991b49421daf6c61ca542c58a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50db9ae15d784bf39da53dbddd874895": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "178a7f466fd74a42876f0225dc64f472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c26c5af2817491583195731d2d5e47e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae89b5aef7a44c208776db604865230d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}